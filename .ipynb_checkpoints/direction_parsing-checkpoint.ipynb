{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65534c2-07fb-409c-8821-e63f5d717792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import pandas as pd\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f59a19a-4513-4c0f-8984-a7c357f449ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up notebook to display multiple outputs in one cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095caca7-5157-4a86-98f8-d91ce4add71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting list of directions, as would be obtained in web_scraping.ipynb\n",
    "directions = ['Preheat the oven to 450 degrees F',\n",
    "              'Pulse the carrots, celery and shallots in a food processor until coarsely chopped',\n",
    "              'Heat 1 tablespoon of the olive oil in a large nonstick skillet over medium high',\n",
    "              'Add the chopped vegetables and cook, stirring frequently, until light golden and soft, 8 to 10 minutes',\n",
    "              '(Add a splash of water if the mixture begins to stick)',\n",
    "              'Add the ground beef and 4 teaspoons of the tomato paste and cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes',\n",
    "              'Add 1/2 cup water, the parsley, raisins, 1 tablespoon of the vinegar and 3/4 teaspoon salt',\n",
    "              'Bring to a simmer and cook until most of the water is absorbed and the mixture gets saucy, about 1 minute',\n",
    "              'Let cool slightly',\n",
    "              'Meanwhile, toss the pepper halves with the remaining 1/2 tablespoon oil in a microwave-safe bowl',\n",
    "              'Cover with plastic wrap and microwave until the peppers are pliable, 10 to 12 minutes',\n",
    "              'Carefully uncover the bowl and pour out any liquid that has accumulated',\n",
    "              'Stir the couscous into the beef mixture',\n",
    "              'Whisk together the remaining 2 tablespoons tomato paste, 1 tablespoon vinegar and 3/4 cup water in the bottom of a large baking dish',\n",
    "              'Carefully transfer the peppers to the baking dish cut-side up and fill each pepper with the couscous mixture',\n",
    "              'Sprinkle with the cheese',\n",
    "              'Cover with foil and bake until the peppers are tender and the stuffing is hot, 20 to 25 minutes',\n",
    "              'Serve warm or at room temperature drizzled with the tomato cooking liquid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9a669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting list of ingredients, as would be obtained in ingredient_parsing.ipynb\n",
    "units_list = [\"ounce\", \"pinch\", \"dash\", \"cup\", \"gallon\", \"pint\", \"milliliter\", \"liter\", \"gram\", \"pound\", \"fluid ounce\", \"kilogram\",\n",
    "             \"spoon\", \"quart\", \"container\", \"can\", \"box\", \"package\", \"packet\", \"tablespoon\", \"teaspoon\"]\n",
    "equipment_list = [\"pot\", \"pan\", \"sheet pan\", \"tray\",\n",
    "                  \"dish\", \"pressure cooker\", \"blender\", \"toaster\",\n",
    "                  \"microwave\", \"stove\", \"oven\", \"range\", \"burner\",\n",
    "                  \"cooktop\", \"measuring cup\", \"cup\", \"bowl\", \"mixing bowl\", \n",
    "                  \"spoon\", \"fork\", \"knife\", \"ladle\", \"spatula\", \"tongs\", \"paddle\", \"strainer\", \"mixer\", \"whisk\",\n",
    "                  \"toothpick\", \"foil\", \"parchment\", \"paper\", \"plastic wrap\", \"paper towel\", \"food processor\", \"skillet\", \"baking dish\"]\n",
    "\n",
    "\n",
    "ingredients =   ['2 medium carrots, cut into chunks', \n",
    "                '2 stalks celery, cut into chunks',\n",
    "                '1 large shallot, cut into chunks'\n",
    "                '1 1/2 tablespoons olive oil',\n",
    "                '1/2 pound lean ground beef',\n",
    "                '2 tablespoons plus 4 teaspoons tomato paste',\n",
    "                '1/3 cup chopped fresh parsley, dill or a combination',\n",
    "                '1/3 cup golden raisins',\n",
    "                '2 tablespoons red wine vinegar',\n",
    "                'Kosher salt',\n",
    "                '4 red, yellow, orange or green bell peppers or a mix of colors, halved lengthwise and seeded',\n",
    "                '1/2 cup whole wheat couscous',\n",
    "                '3/4 cup grated asiago cheese']\n",
    "\n",
    "# Strip away stopwords, predetermined units and/or equipment from list of ingredients for direction parsing purposes\n",
    "inflection_engine = inflect.engine()\n",
    "for ingredient_idx, i in enumerate(ingredients):\n",
    "    ingredients[ingredient_idx] = i.replace(',', \"\")\n",
    "    new_sentence = ingredients[ingredient_idx]\n",
    "    for word in ingredients[ingredient_idx].split(\" \"):\n",
    "        # for stopword in stopwords.words('english'):\n",
    "        #     if word == stopword: \n",
    "        #         print(word, stopword)\n",
    "        #         new_sentence = new_sentence.replace(word, \"\")\n",
    "        for unit in units_list:\n",
    "            if word == unit or word == inflection_engine.plural(unit): \n",
    "                new_sentence = new_sentence.replace(word, \"\")\n",
    "        for equipment in equipment_list:\n",
    "            if word == equipment: \n",
    "                new_sentence = new_sentence.replace(word, \"\")\n",
    "    ingredients[ingredient_idx] = new_sentence\n",
    "\n",
    "ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de10fdf-0b8f-4240-8ad7-700a44c5caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_dep_df = pd.DataFrame(columns = ['direction_index', 'word', 'pos_coarse', 'pos_fine', 'dependency', 'parent'])\n",
    "\n",
    "for i in range(len(directions)):\n",
    "    # Creating a Doc object from the directions\n",
    "    direction_doc = nlp(directions[i])\n",
    "    # Visualize the dependency relations\n",
    "    #displacy.render(direction_doc, style = \"dep\")\n",
    "    # Dependency parsing the directions\n",
    "    for token in direction_doc:\n",
    "        new_row = {'direction_index': i, 'word': token.text, 'pos_coarse': token.pos_, 'pos_fine': token.tag_, 'dependency': token.dep_, 'parent': token.head}\n",
    "        direction_dep_df = direction_dep_df.append(new_row, ignore_index = True)\n",
    "\n",
    "print(direction_dep_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438400c3-d7fd-40f7-9fb6-4ed53e3b9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://www.reddit.com/r/LanguageTechnology/comments/egh7jk/how_to_check_if_a_word_can_be_interpreted_as_a/ for purposes of determining whether or not a given direction should be split up\n",
    "def possible_verb(surface): \n",
    "    return 'v' in set(s.pos() for s in wordnet.synsets(surface))\n",
    "\n",
    "print(possible_verb(\"4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa95dc-8d45-4f88-af4e-d5416bc5b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inflection_engine = inflect.engine()\n",
    "\n",
    "unit_conversion = {\"oz\": \"ounce\", \"c\": \"cup\", \"pt\": \"pint\", \"gal\": \"gallon\", \"ml\": \"milliliter\", \"mL\": \"milliliter\",\n",
    "                  \"g\": \"gram\", \"lb\": \"pound\", \"kg\": \"kilogram\", \"kilo\": \"kilogram\", \"qt\": \"quart\", \"l\": \"liter\", \"L\": \"liter\",\n",
    "                  \"tb\": \"tablespoon\", \"tbs\": \"tablespoon\", \"tbsp\": \"tablespoon\", \"tsp\": \"teaspoon\"}\n",
    "units_of_time_list = [\"second\", \"seconds\", \"minute\", \"minutes\", \"hour\", \"hours\"]\n",
    "temp_levels_list = [\"low\", \"medium\", \"high\", \"simmer\", \"boil\"] \n",
    "\n",
    "direction_df = pd.DataFrame(columns = ['direction_index', 'raw_text', 'action', 'action_duration', 'action_temperature', 'action_details', 'ingredient_amount', 'ingredient_unit', 'ingredient_name', 'equipment'])\n",
    "direction_index = 0\n",
    "current_direction_length = len(directions)\n",
    "while direction_index < current_direction_length:\n",
    "    if direction_index >= 5 and direction_index < 10: print(\"\\n\".join(directions))\n",
    "    # Creating a Doc object from the directions\n",
    "    direction_doc = nlp(directions[direction_index])\n",
    "    # Pulling out the relevant information from the dependency parsed directions\n",
    "    raw_text = direction_doc.text\n",
    "    action = \"\"\n",
    "    action_duration = \"\"\n",
    "    action_temperature = \"\"\n",
    "    action_details = \"\"\n",
    "    ingredient_amount = [] # stored as array so that corresponding unit can be retrieved w/ the same idx\n",
    "    ingredient_unit = []  # stored as array so that corresponding amount can be retrieved w/ the same idx\n",
    "    ingredient_name = set()\n",
    "    equipment = []\n",
    "    direction_not_split = True\n",
    "    for token_index, token in enumerate(direction_doc):\n",
    "        token_is_action_preceded_by_and = possible_verb(token.text) and direction_doc[token_index-1].text == 'and'\n",
    "        token_is_root = token.dep_ == 'ROOT'\n",
    "        token_is_lower_range_of_action_duration = token.dep_ == 'quantmod' and token.head.dep_== 'nummod'\n",
    "        token_is_higher_range_of_action_duration = token.dep_ == 'nummod' and token.head.text in units_of_time_list\n",
    "        token_is_action_temperature = token.dep_ == 'nummod' and token.head.text == 'degrees'\n",
    "        token_is_action_temperature_unit = (token.text == 'F' or re.match('[Ff]ahrenheit', token.text)) or (token.text == 'C' or re.match('[Cc]elsius', token.text))\n",
    "        token_is_ingredient_amount_and_abbreviated_unit = direction_doc[token_index-1].pos_ == 'NUM' and token.text in unit_conversion.keys() and unit_conversion[token.text] in units_list\n",
    "        token_is_ingredient_amount_and_unit = direction_doc[token_index-1].pos_ == 'NUM' and (token.text in units_list or inflection_engine.plural(token.text) in units_list)\n",
    "\n",
    "        if token_is_action_preceded_by_and:\n",
    "            '''\n",
    "                A WEIRD BUG / EDGE CASE\n",
    "                -----------------------\n",
    "                In the end, the code below is splitting the following instruction in the following manner:\n",
    "\n",
    "                \"Add the ground beef and 4 teaspoons of the tomato paste and cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "                =>\n",
    "                \"Add the ground beef\",\n",
    "                \"4 teaspoons of the tomato paste\",\n",
    "                \"Cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "\n",
    "                Somehow this is done in two steps, i.e.:\n",
    "                \n",
    "                1. \"Add the ground beef and 4 teaspoons of the tomato paste and cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "                    =>\n",
    "                    \"Add the ground beef and 4 teaspoons of the tomato paste\",\n",
    "                    \"Cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "                2. \"4 teaspoons of the tomato paste and cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "                    =>\n",
    "                    \"4 teaspoons of the tomato paste\",\n",
    "                    \"Cook, breaking the mixture up with a wooden spoon, until browned, about 4 minutes\"\n",
    "\n",
    "                The existence of the raw text on the 2nd step is what confuses me, as the original direction should never be split on \"...and 4 teaspoons...\", and yet somehow the final output has this as a sub-direction with \"teaspoons\" as the root/action\n",
    "            '''\n",
    "            and_space_str = \"and \"\n",
    "            idx_of_and_action = raw_text.index(and_space_str + token.text)\n",
    "            split_raw_text = raw_text.split(and_space_str, 1)\n",
    "            first_half_of_raw_text = raw_text[ : idx_of_and_action]\n",
    "            second_half_of_raw_text = raw_text[ idx_of_and_action + len(and_space_str) :].capitalize()\n",
    "            # print(\"\\n\")\n",
    "            # print(\"Action to Split On:\", token.text)\n",
    "            # print(\"Raw Text:\", raw_text)\n",
    "            # print(\"First half:\", first_half_of_raw_text)\n",
    "            # print(\"Second half:\", second_half_of_raw_text)\n",
    "            # print(\"Replaced dir:\", directions[direction_index])\n",
    "            # print(\"\\n\")\n",
    "            # alter directions array to reflect new sub-directions\n",
    "            directions[direction_index] = split_raw_text[0] # Replace the original direction string with the first new direction\n",
    "            directions.insert(direction_index+1, split_raw_text[1].capitalize()) # Insert the second new direction after the first\n",
    "            current_direction_length += 1\n",
    "            direction_not_split = False\n",
    "            break\n",
    "        elif token_is_root:\n",
    "            action = token.text\n",
    "        elif token_is_lower_range_of_action_duration:\n",
    "            action_duration += token.text + ' '\n",
    "        elif token_is_higher_range_of_action_duration:\n",
    "            action_duration += token.text + ' ' + token.head.text\n",
    "        elif token_is_action_temperature:\n",
    "            action_temperature = token.text + ' ' + token.head.text\n",
    "        elif token_is_action_temperature_unit:\n",
    "            action_temperature += ' ' + token.text\n",
    "        elif token_is_ingredient_amount_and_abbreviated_unit:\n",
    "            ingredient_amount.append(direction_doc[token_index-1].text)\n",
    "            ingredient_unit.append(unit_conversion[token.text])\n",
    "        elif token_is_ingredient_amount_and_unit:\n",
    "            ingredient_amount.append(direction_doc[token_index-1].text)\n",
    "            ingredient_unit.append(token.text)\n",
    "        else:\n",
    "            for i in ingredients:\n",
    "                plural_version = inflection_engine.plural(token.text)\n",
    "                if (token.text in i or plural_version in i) and token.pos_ != 'NUM':\n",
    "                    ingredient_name.add(token.text)\n",
    "            for e in equipment_list:\n",
    "                if token.text == e:\n",
    "                    equipment_string = ''\n",
    "                    equipment_adj_idx = token_index-1\n",
    "                    while equipment_adj_idx > 0 and direction_doc[equipment_adj_idx].head.text == token.text and direction_doc[equipment_adj_idx].dep_ != 'det':\n",
    "                        equipment_string = direction_doc[equipment_adj_idx].text + ' ' + equipment_string\n",
    "                        equipment_adj_idx -= 1\n",
    "                    equipment_string += token.text\n",
    "                    equipment.append(equipment_string)\n",
    "    \n",
    "    if direction_not_split:\n",
    "        new_row = {'direction_index': direction_index, 'raw_text': raw_text, 'action': action, 'action_duration': action_duration, 'action_temperature': action_temperature, 'action_details': action_details, 'ingredient_amount': ingredient_amount, 'ingredient_unit': ingredient_unit, 'ingredient_name': ingredient_name, 'equipment': equipment}\n",
    "        direction_df = direction_df.append(new_row, ignore_index = True)\n",
    "        direction_index += 1\n",
    "\n",
    "direction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3dea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
